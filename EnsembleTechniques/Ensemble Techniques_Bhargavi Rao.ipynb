{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bank Marketing - Term Deposit Sale analysis and Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal of the project is to build multiple models that can predict the bank clients likelihood to subscribe to term deposit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt# matplotlib.pyplot plots data\n",
    "%matplotlib inline \n",
    "from sklearn.model_selection import train_test_split\n",
    "import missingno as msno\n",
    "import warnings\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('bank-full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique() ## Getting the unique columns from each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic checks on the data prior to analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_checks(df):\n",
    "    \n",
    "    print('='*50)\n",
    "    print('Shape of the dataframe is: \\n',df.shape)\n",
    "    print('='*50)\n",
    "    print('Basic stats for the data: \\n',df.describe())\n",
    "    print('='*50)\n",
    "    print('Data type and info :')\n",
    "    print(df.info())\n",
    "    print('='*50)\n",
    "    print('Missing value information : \\n',df.isnull().any())\n",
    "    print('='*50)\n",
    "    print('Sum of missing values if any : \\n',df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_checks(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values are seen in the data set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Univariate and bivariate analysis of the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting correlations between the variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "sns.heatmap(data.corr(),\n",
    "            annot=True,\n",
    "            linewidths=.5,\n",
    "            center=0,\n",
    "            cbar=False,\n",
    "            cmap=\"YlGnBu\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA Part 1 \n",
    "\n",
    "Basic stats\n",
    "\n",
    "1.The data set has 45211 records and 17 variables.\n",
    "2.Average age of the clients is 40.9 ,with 18 being the smallest and 95 being the highest age .\n",
    "3.Average account balance is 1362 ,with minimum at -8019 and 102127\n",
    "4.last contact duration is at an average of 4.3 minutes\n",
    "5.An average of 2.7 contacts were made with the customer during this campaign.\n",
    "6.A majority of the clients seem to not be contacted for more than 900 days or they have not been contacted at all.\n",
    " \n",
    "Data Types :\n",
    "\n",
    "There seems to be a good mix of categorical and continuous variables in this dataset ,some continuous variables ,like age,balanace,pdays,would need to be further processed to understand the data better.\n",
    "\n",
    "Missing values:\n",
    "\n",
    "We do not see any missing values in this dataset\n",
    "\n",
    "Correlation between the variables :\n",
    "\n",
    "1.Campaign and day are very slightly correlated.\n",
    "2.pdays and previous seem to be slightly correlated at 0.45 score . \n",
    "3.There is no significant correlation between the other variables in the dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate and bivariate plots - Continous variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(variable):\n",
    "    fig=plt.figure(figsize=(10,5))\n",
    "    plt.subplot(221)\n",
    "    sns.distplot(data[variable])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.subplot(222)\n",
    "    sns.boxplot(x=data[variable])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.subplot(223)\n",
    "    sns.boxplot(x=data['Target'],y=data[variable])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.subplot(224)\n",
    "    sns.barplot(x='Target',y=data[variable],data=data)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age,Balance,day,duration,campaign,pdays and previous are int data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_cat(x):\n",
    "    if (x>=18)&(x<=35):\n",
    "        return 0\n",
    "    else :\n",
    "        if(x>35)&(x<=50):\n",
    "            return 1\n",
    "        else: \n",
    "            if (x>50)&(x<=65):\n",
    "                return 2\n",
    "            else:\n",
    "                if (x>65):\n",
    "                    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_category']=data['age'].apply(age_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('age_category',hue='Target',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.countplot('age_category',hue='Target',data=data[data['Target']=='yes']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=[0,1,2,3]\n",
    "\n",
    "for i in cats:\n",
    "    a=data[(data['age_category']==i)&(data['Target']=='yes')].shape[0]\n",
    "    b=data[data['age_category']==i].shape[0]\n",
    "    print('Proportions for age category {} is: {}%'.format(i,np.round(a/b*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots('balance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15,5))\n",
    "sns.distplot(data[(data['balance']>-9000) & (data['balance']<10000)]['balance']);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data seems to be extremely right skewed ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the balance variable further to see the spread of the data.\n",
    "We 1st define a function which will bucket the balance to individual categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bal_cat(x):\n",
    "        if (x>-8110) & (x<-2000):\n",
    "            return 0\n",
    "        else:\n",
    "            if (x >= -2000) & (x <0):\n",
    "                return 1\n",
    "            else:\n",
    "                if (x >=0) & (x < 3000):\n",
    "                    return 2\n",
    "                else:\n",
    "                    if (x >=3000) & (x < 6000):\n",
    "                        return 3\n",
    "                    else: \n",
    "                        if (x >=6000) & (x < 8000):\n",
    "                                return 4\n",
    "                        else: \n",
    "                            if x >= 8000:\n",
    "                                return 5      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['balance_category']=data['balance'].map(bal_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance distribution for those clients that subscribed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.countplot('balance_category',hue='Target',data=data[data['Target']=='yes']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the balance category 2 is the most common ,i.e balance>0 and lesser than 3000 ,\n",
    "followed by customers that have a balance of 6000-8000.\n",
    "\n",
    "Further exploring how the target variables change with these popular account balance bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('balance_category',hue='Target',data=data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=[0,1,2,3,4,5]\n",
    "for i in cats:\n",
    "    a=data[(data['balance_category']==i) & (data['Target']=='yes')].shape[0]\n",
    "    b=data[data['balance_category']==i].shape[0]\n",
    "    print('Subscriptions % for balance category : {} is {}%'.format(i,np.round(a/b*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest band with the deposit subscribed is category 3(as a % of those in teh same category),5&4 respectively .So any account balance >3000 have subscribed to the term deposit better relatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=[0,1,2,3,4,5]\n",
    "for i in cats:\n",
    "    a=data[(data['balance_category']==i) & (data['Target']=='yes')].shape[0]\n",
    "    b=data['balance_category'].count()\n",
    "    print('Subscriptions % for balance category {}  against overall is: {}%'.format(i,np.round(a/b*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots('day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_cat(x):\n",
    "    if (x>=1)&(x<=7):\n",
    "        return 0\n",
    "    else:\n",
    "        if (x>8)&(x<=23):\n",
    "            return 1\n",
    "        else:\n",
    "            if (x>24)&(x<=31):\n",
    "                return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['day_category']=data['day'].apply(days_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data['day_category'],hue='Target',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('day_category',hue='Target',data=data[data['Target']=='yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=[0,1,2]\n",
    "\n",
    "for i in cats:\n",
    "    a=data[(data['day_category']==i)&(data['Target']=='yes')].shape[0]\n",
    "    b=data[data['day_category']==i].shape[0]\n",
    "    print('Proportions for day category {} is: {}%'.format(i,np.round(a/b*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots('duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the cuberoot transformed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['duration']=np.cbrt(data['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration for the call follows a similar trend for both deposit subscribed users and thos that did not .The majority of users that have subscribed have a last contact duration less than 6 mins . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots('campaign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['campaign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camp_cat(x):\n",
    "    if (x>0)&(x<3):\n",
    "        return 0\n",
    "    else :\n",
    "        if(x>=3)&(x<10):\n",
    "            return 1\n",
    "        else: \n",
    "            if (x>10):\n",
    "                return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['campaign_category']=data['campaign'].apply(camp_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('campaign_category',hue='Target',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('campaign_category',hue='Target',data=data[data['Target']=='yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its clear that most customers have been contacted less than 10 times.The customers who have subscribed to the term deposit have been contacted less than 3 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig=plt.figure(figsize=(10,5))\n",
    "plt.subplot(131)\n",
    "sns.distplot(data['previous'],kde=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.subplot(132)\n",
    "sns.boxplot(x=data['previous'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.subplot(133)\n",
    "sns.boxplot(x=data['Target'],y=data['previous'])\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['previous'],kde=False)\n",
    "plt.xlim(0,100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning the data into 3 categories as below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_cat(x):\n",
    "    if (x>=0)&(x<5):\n",
    "        return 0\n",
    "    else:\n",
    "        if (x>=5)&(x<20):\n",
    "            return 1\n",
    "        else:\n",
    "            if (x>=20):\n",
    "                return 2       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['previous_category']=data['previous'].apply(previous_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('previous_category',hue='Target',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('previous_category',hue='Target',data=data[data['Target']=='yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very clearly a majority were contacted less than 5 times before this campaign ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### pdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig=plt.figure(figsize=(10,5))\n",
    "plt.subplot(131)\n",
    "sns.distplot(data['pdays'],kde=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.subplot(132)\n",
    "sns.boxplot(x=data['pdays'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.subplot(133)\n",
    "sns.boxplot(x=data['Target'],y=data['pdays'])\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['pdays'],kde=False)\n",
    "plt.xlim(-10,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning into categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdays_cat(x):\n",
    "    if (x<1):\n",
    "        return 0\n",
    "    else:\n",
    "        if(x>=1)&(x<30):\n",
    "            return 1\n",
    "        else:\n",
    "            if(x>=30)&(x<100):\n",
    "                return 2\n",
    "            else:\n",
    "                if(x>=100):\n",
    "                    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pdays_category']=data['pdays'].apply(pdays_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data['pdays_category'],hue='Target',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('pdays_category',hue='Target',data=data[data['Target']=='yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=[0,1,2,3]\n",
    "\n",
    "for i in cats:\n",
    "    a=data[(data['pdays_category']==i)&(data['Target']=='yes')].shape[0]\n",
    "    b=data[data['pdays_category']==i].shape[0]\n",
    "    print('Proportions for pdays category {} is: {}%'.format(i,np.round(a/b*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=[0,1,2,3]\n",
    "\n",
    "for i in cats:\n",
    "    a=data[(data['pdays_category']==i)&(data['Target']=='yes')].shape[0]\n",
    "    b=data['pdays_category'].count()\n",
    "    print('Proportions for pdays category  {} against overall is :{}%'.format(i,np.round(a/b*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA - Part 2 \n",
    "\n",
    "##### Univariate and bivariate analysis - Continuous variables\n",
    "\n",
    "Breaking the analysis down to each variable and understanding the relationship between the variables and the target we proceed to Univariate and Bivariate analysis \n",
    "\n",
    "Age:\n",
    "1.Age is slightly right skewed data ,the customers are majorly between the ages 20-60.There’s a few outliers in the dataset after age 70 for the overall data and for the subscription data has outliers above age 80.\n",
    "We will need to bin this data to generate meaningful insights as the current distribution does not allow us to visualise the insights.\n",
    "2.The age range that has subscribed to term deposit ranges from 20 to above 80, with the median lying at 40.Number of subscribers are the highest in the age range 18-35 followed by 35 and 50. However,the % of subscribers for term deposit is highest for clients over 65 years .\n",
    "\n",
    "Balance:\n",
    "1. Balance data is extremely right skewed .There’s a lot of outliers in the data ,the distribution of the data is hard just looking at the graphs, the minimum balance is -8019 and the highest is at 102127.We will need to bin this variable to see how the data is distributed between those that subscribed and those that did not.\n",
    "2. We see that the  balance>0 and less than 3000 ,followed by customers that have a balance of 6000-8000 are the most common for those clients that subscribed.Further exploring how the target variables change with these popular account balance bands.\n",
    "3. The highest conversion with the deposit subscription is account balances >3000 .\n",
    "\n",
    "Day:\n",
    "1. Last contact day of the month doesn’t seem to be showing any particular trend.Although set as a continuous variable it would be useful to see if binning would help in understanding the last contact day of the month better.\n",
    "2. We bin this variable based on days>1&<7, days>8&<=23 and anything else in another category \n",
    "3. Although there may not be a direct correlation between the target variable and the last contact day ,the data shows that those contacted in 1st week of the month show better conversion than others .This could be combined with multiple other factors to see why the conversion is better in the 1st week.\n",
    "\n",
    "Duration:\n",
    "1.Duration again ,may not directly impact the subscription conversion .We see that this is a continuous variable and the data is extremely right skewed\n",
    "2. Duration for the call follows a similar trend for both deposit subscribed users and those that did not .The majority of users that have subscribed have a last contact duration less than 6 mins . Since the data is extremely skewed ,we need a transformation technique to normalise the data .Hence we apply the cube root transformation to this data.\n",
    "\n",
    "Campaign : \n",
    "1. The data is extremely right skewed here and a good way to see the data distribution would be by binning the data and seeing the patterns.\n",
    "2. Its clear that most customers have been contacted less than 10 times.The customers who have subscribed to the term deposit have been contacted less than 3 times.\n",
    "\n",
    "Previous:\n",
    "1. As with most of the other variables the data in previous needs transformation as this is clearly skewed.\n",
    "2. From previous variable data,Very clearly a majority were contacted less than 5 times before this campaign .Those that subscribed had also been contacted less than 5 times.\n",
    "\n",
    "pdays:\n",
    "1. This variable is skewed too and we will bin the days to see if there’s any pattern in the data\n",
    "2. Pdays- There is a very high customer base that has either not been contacted at least once or in the last 900 days .We see that approximately 50 % of the customers that have subscribed have not been contacted in the past 100 days .19% of the customers that subscribed haven’t been contacted for more than 100 days.This clearly highlights the potential in marketing to the clients  who haven’t subscribed to convert them.\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Countplots for the categorical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catplot(variable):\n",
    "    fig=plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.xticks(rotation=90)\n",
    "    sns.countplot(x=variable,data=data)\n",
    "    plt.subplot(1,2,2)\n",
    "    sns.countplot(x=variable, hue='Target', data=data)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catplot('job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('job',hue='Target',data=data[data['Target']=='yes'])\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=['management','technician','blue-collar','admin.']\n",
    "\n",
    "for i in cats:\n",
    "    a=data[(data['job']==i)&(data['Target']=='yes')].shape[0]\n",
    "    b=data[data['job']==i].shape[0]\n",
    "    print('Proportions for job category {} is: {}%'.format(i,np.round(a/b*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catplot('marital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('marital',hue='Target',data=data[data['Target']=='yes'])\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=['married','single','divorced']\n",
    "\n",
    "for i in cats:\n",
    "    a=data[(data['marital']==i)&(data['Target']=='yes')].shape[0]\n",
    "    b=data[data['marital']==i].shape[0]\n",
    "    print('Proportions for marital category {} is: {}%'.format(i,np.round(a/b*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catplot('education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('education',hue='Target',data=data[data['Target']=='yes'])\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=['secondary','tertiary','unknown','primary']\n",
    "\n",
    "for i in cats:\n",
    "    a=data[(data['education']==i)&(data['Target']=='yes')].shape[0]\n",
    "    b=data[data['education']==i].shape[0]\n",
    "    print('Proportions for education category {} is: {}%'.format(i,np.round(a/b*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catplot('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('default',hue='Target',data=data[data['Target']=='yes'])\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=['yes','no']\n",
    "\n",
    "for i in cats:\n",
    "    a=data[(data['default']==i) & (data['Target']=='yes')].shape[0]\n",
    "    b=data[data['default']==i].shape[0]\n",
    "    print('Subscriptions % for default category {} is: {}%'.format(i,np.round(a/b*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catplot('housing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('housing',hue='Target',data=data[data['Target']=='yes'])\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=['yes','no']\n",
    "\n",
    "for i in cats:\n",
    "    a=data[(data['housing']==i) & (data['Target']=='yes')].shape[0]\n",
    "    b=data[data['housing']==i].shape[0]\n",
    "    print('Subscriptions % for housing category {} is: {}%'.format(i,np.round(a/b*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catplot('loan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('loan',hue='Target',data=data[data['Target']=='yes'])\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=['yes','no']\n",
    "\n",
    "for i in cats:\n",
    "    a=data[(data['loan']==i) & (data['Target']=='yes')].shape[0]\n",
    "    b=data[data['loan']==i].shape[0]\n",
    "    print('Subscriptions % for loan category {} is: {}%'.format(i,np.round(a/b*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catplot('contact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('contact',hue='Target',data=data[data['Target']=='yes'])\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=['unknown','cellular','telephone']\n",
    "\n",
    "for i in cats:\n",
    "    a=data[(data['contact']==i) & (data['Target']=='yes')].shape[0]\n",
    "    b=data[data['contact']==i].shape[0]\n",
    "    print('Subscriptions % for contact category {} is: {}%'.format(i,np.round(a/b*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catplot('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('month',hue='Target',data=data[data['Target']=='yes']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_cat(x):\n",
    "    if (x=='apr')|(x=='may')|(x=='jun'):\n",
    "        return 'Q1'\n",
    "    else:\n",
    "        if (x=='jul')|(x=='aug')|(x=='sep'):\n",
    "            return 'Q2'\n",
    "        else:\n",
    "            if (x=='oct')|(x=='nov')|(x=='dec'):\n",
    "                return 'Q3'\n",
    "            else:\n",
    "                if (x=='jan')|(x=='feb')|(x=='mar'):\n",
    "                    return 'Q4'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['month_category']=data['month'].apply(month_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('month_category',hue='Target',data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### poutcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catplot('poutcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('poutcome',hue='Target',data=data[data['Target']=='yes'])\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=['unknown','other','failure','success']\n",
    "\n",
    "for i in cats:\n",
    "    a=data[(data['poutcome']==i) & (data['Target']=='yes')].shape[0]\n",
    "    b=data[data['poutcome']==i].shape[0]\n",
    "    print('Subscriptions % for poutcome category : {} is {}%'.format(i,np.round(a/b*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.7 % of the overall customer data indicates subsriction to the term deposit .88.3 % of the customers hadn't subscribed to the term deposit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes to other attributes with respect to the dependant variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['Target']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['Target']).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA Part 2 - categorical variables & Target variable distribution\n",
    "\n",
    "`Categorical variable distribution`\n",
    "\n",
    "Job\n",
    "\n",
    "1.From the overall numbers blue-collar, management,technician,admin and services respectively seem to be popular options.\n",
    "2.For those that subscribed to the term deposit, the job popular categories are Management, Technician, blue-collar & admin respectively.The job % split for subscribed customers is Management -13.76%,technician-11.06%,admin-12.2%,blue-collar-7.27%.\n",
    "\n",
    "Marital\n",
    "1.Most subscribed customers are married followed by single and divorced categories.\n",
    "2.Of the married customer population 10.12% have subscribed and 14.95% from the single category have subscribed to term deposit ,divorced customers are the one’s that are least to subscribe.\n",
    "\n",
    "Education\n",
    "1.Secondary education level is most popular followed by tertiary and primary in the subscribed customers.\n",
    "2.The highest subscriptions are for tertiary education category at 15% followed by unknown category at 13.5%\n",
    "\n",
    "Default\n",
    "1.8 % of the overall population has credit in default.Those that have not been defaulted have a population of 11.8% conversion\n",
    "\n",
    "Housing\n",
    " Approximately 55.6 % have a housing loan.16.7% of those that do not have a housing loan have subscribed to the term deposit.\n",
    "\n",
    "Loan\n",
    "\n",
    "84% of the customers do not have personal loan ,of the customers that don’t have a personal loan 12.6% subscribed to the loan and 6.6% from those that have a personal loan.\n",
    "\n",
    "Contact\n",
    "Most popular communication type is Cellular phone, followed by unknown and telephone.Those that have subscribed have been contacted using cell phone .\n",
    "\n",
    "Month\n",
    "Most popular subscription month is May,Aug,July,April followed by June. The data has been bucketed to make it more meaningful to understand subscriptions by quarter.Q1 (Apr,May,Jun) has the highest subscriptions followed by Q2(Jul,Aug,Sep) .\n",
    "\n",
    "poutcome\n",
    "The outcome of the previous campaign is majorly unknown.Of those that have the outcome category as success 64.73% have subscribed to the term deposit.\n",
    "\n",
    "\n",
    "`Target variable distribution:`\n",
    "\n",
    "1. 11.7 % of the overall customer data indicates subscription to the term deposit .88.3 % of the customers hadn't subscribed to the term deposit.\n",
    "2. Average age of the client that subscribed to the term deposit is 38.\n",
    "3. Average account balance is 1804.26 for those that opted subscription.\n",
    "4. An average of 2-3 contacts were made during the campaign for both clients that subscribed and those that did not.\n",
    "5. An average of 70 days passed after the last contact for the client to subscribe to the term deposit.\n",
    "6. At least 1 contact was made before the campaign with the clients that subscribed as opposed to those that did not .\n",
    "7. There’s a clear bias in the data distribution of the variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Getting the data model ready (Deliverable 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['balance_category']=data['balance_category'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['campaign_category']=data['campaign_category'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['previous_category']=data['previous_category'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pdays_category']=data['pdays_category'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_category']=data['age_category'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['day_category']=data['day_category'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation for modeling \n",
    "\n",
    "1.In EDA,we have created a few categorical variables for continuous variables that did not have normal distribution and also needed binning to get clearer insight.\n",
    "\n",
    "2.Checking the datatypes of the variables and converting the new variables created to categorical where needed ,since we applied binning to a few continuous variables and created new variables\n",
    "\n",
    "3.Dropping the old variables as we may not need some continuous variables after they have been binned.\n",
    "\n",
    "4.Mapping the data with categories ‘yes’ &’no’ to 1 & 0 for the variables Target,Default,Loan & Housing.\n",
    "\n",
    "5.We will then split the data into Train and Test data and check the split was done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data2.drop(['age','balance','day','month','campaign','pdays','previous'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_map={'yes':1,'no':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat(x):\n",
    "    if (x=='yes'):\n",
    "        return 1\n",
    "    else:\n",
    "        if(x=='no'):\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Target']=data2['Target'].apply(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['default']=data2['default'].apply(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['loan']=data2['loan'].apply(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['housing']=data2['housing'].apply(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Split the data into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.get_dummies(data2.drop('Target',axis=1),drop_first=True)\n",
    "Y=data2['Target']\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0:0.2f}% data is in training set\".format((len(x_train)/len(data2.index)) * 100))\n",
    "print(\"{0:0.2f}% data is in test set\".format((len(x_test)/len(data2.index)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Target True Values    : {0} ({1:0.2f}%)\".format(len(data2.loc[data2['Target'] == 1]), (len(data2.loc[data2['Target'] == 1])/len(data2.index)) * 100))\n",
    "print(\"Original Target Loan False Values   : {0} ({1:0.2f}%)\".format(len(data2.loc[data2['Target'] == 0]), (len(data2.loc[data2['Target'] == 0])/len(data2.index)) * 100))\n",
    "print(\"\")\n",
    "print(\"Training Target True Values    : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 1]), (len(y_train[y_train[:] == 1])/len(y_train)) * 100))\n",
    "print(\"Training Target False Values   : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 0]), (len(y_train[y_train[:] == 0])/len(y_train)) * 100))\n",
    "print(\"\")\n",
    "print(\"Test Target True Values        : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 1]), (len(y_test[y_test[:] == 1])/len(y_test)) * 100))\n",
    "print(\"Test Target False Values       : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 0]), (len(y_test[y_test[:] == 0])/len(y_test)) * 100))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics to focus on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Business Insights`\n",
    "\n",
    "True Negative (observed=0,predicted=0)\n",
    "\n",
    "Predicted that the customer would not subscribe and they actually do not.\n",
    "\n",
    "False Positive (observed=0,predicted=1)\n",
    "\n",
    "Predicted that the customer would subscribe while the customer did not.\n",
    "\n",
    "True Negative (observed=0,predicted=0)\n",
    "\n",
    "Predicted that the customer would not subscribe and the customer did not.\n",
    "\n",
    "False Negative(observed=1,predicted=0)\n",
    "\n",
    "Predicted the customer would not subscribe when the customer did.\n",
    "\n",
    "`From the points above we know that we should be focusing on`\n",
    "\n",
    "Low False Negatives as False negatives would mean missed opportunity for the bank in predicting clients who could convert as fixed term subscribers.\n",
    "\n",
    "High score of True positives which would mean the prediction on the fixed term subscribers would be accurate.\n",
    "\n",
    "False Positives in this case could be relatively harmless as this would not mean that the bank would lose money.\n",
    "\n",
    "`Metrics of main interest`\n",
    "\n",
    "Our fundamental assumption here is that we want to figure out customers that convert as subscribers of deposit for the term\n",
    "\n",
    "1. Recall  \n",
    "2. ROC/AUC Score\n",
    "\n",
    "While trying to look at the above 2 metrics,we would also want to balance the following for a decent score \n",
    "\n",
    "1. Accuracy \n",
    "2. F1 Score\n",
    "3. Precision\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling\n",
    "\n",
    "To achieve a good score of recall ,ROC/AUC ,we model the data using different models like \n",
    "1. Logistic Regression \n",
    "2. Decision Trees \n",
    "3. Random Forest Classifier \n",
    "4. Adaboost Classifier \n",
    "5. Gradientboost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Logistic Regression- Modeling steps`\n",
    "\n",
    "1. Build a basic Logistic regression with default parameters.Note the accuracy, recall, precision,F1 score and ROC AUC score.\n",
    "2. Tweak the parameters - C,Solver, to see any improvement in the model performance.\n",
    "3. Balance the data to improve the performance measures.\n",
    "4. Compare the performance measures, print the confusion matrix and pick the model that gives us the best Recall,ROC AUC scores ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## Fitting the model on training set\n",
    "\n",
    "model=LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "## Predicting on test set\n",
    "\n",
    "y_predict=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Model Scores on Train & Test Data set ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score=model.score(x_test,y_test)\n",
    "print(model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score=model.score(x_train,y_train)\n",
    "print(model_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test datasets show good model score .Lets us now print the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix=metrics.confusion_matrix(y_test,y_predict)\n",
    "print('The confusion matrix is printed below')\n",
    "print('')\n",
    "\n",
    "print(confusion_matrix)\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test,y_predict)\n",
    "sns.heatmap(cm,annot=True,  fmt='.2f', xticklabels = [0,1] , yticklabels = [0,1])\n",
    "plt.ylabel('Observed')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy,Precision,Recall,ROC_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,recall_score,precision_score,f1_score,roc_auc_score,accuracy_score,roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy\n",
    "\n",
    "print('Training Accuracy is :',model.score(x_train,y_train))\n",
    "print('')\n",
    "     \n",
    "print('Testing Accuracy is:',model.score(x_test,y_test))\n",
    "print('')\n",
    "\n",
    "## Precision\n",
    "print('Precision of the model is :',metrics.precision_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##Recall \n",
    "print('Recall of the model is:',metrics.recall_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##F1 score \n",
    "print('The F1 score is:',metrics.f1_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##ROC Auc score \n",
    "print('The ROC AUC score is :',metrics.roc_auc_score(y_test,y_predict))\n",
    "print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC/AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(y_test, model.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the Model accuracy is high the recall and ROC/AUC score could definitely be improved ,We would therefore try to improve our model by tuning the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving Model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the model with different solvers,to see if there's an improvement in the scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score=[]\n",
    "test_score=[]\n",
    "solver=['newton-cg','lbfgs','liblinear','sag', 'saga']\n",
    "\n",
    "for i in solver:\n",
    "    model=LogisticRegression(random_state=None,penalty='l2', C = 1,solver=i)\n",
    "    model.fit(x_train,y_train)\n",
    "    y_predict=model.predict(x_test)\n",
    "    train_score.append(round(model.score(x_train,y_train),2))\n",
    "    test_score.append(round(model.score(x_test,y_test),2))\n",
    "    \n",
    "print(solver)\n",
    "print()\n",
    "print(train_score)\n",
    "print()\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking 'saga' solver ,we pick this and proceed with tweaking the C value  to see if it improves the recall and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model \n",
    "\n",
    "model=LogisticRegression(random_state=None,penalty='l2', C = 1,solver='saga')\n",
    "model.fit(x_train,y_train)\n",
    "y_predict=model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score=[]\n",
    "test_score=[]\n",
    "\n",
    "C=[0.01,0.1,0.25,0.5,0.75,1]\n",
    "\n",
    "for i in C :\n",
    "    model=LogisticRegression(random_state=None,penalty='l2', C = i ,solver='saga')\n",
    "    model.fit(x_train,y_train)\n",
    "    y_predict=model.predict(x_test)\n",
    "    train_score.append(round(model.score(x_train,y_train),3))\n",
    "    test_score.append(round(model.score(x_test,y_test),3))\n",
    "  \n",
    "print(C)\n",
    "print()\n",
    "print(train_score)\n",
    "print()\n",
    "print(test_score)\n",
    "\n",
    "#print(metrics.f1_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will stick to C=1 which is the default value as there's no change in the accuracy of the model with other C values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy\n",
    "model=LogisticRegression(random_state=None,penalty='l2',solver='saga',C=1)\n",
    "model.fit(x_train,y_train)\n",
    "y_predict=model.predict(x_test)\n",
    "\n",
    "print('Training Accuracy is :',model.score(x_train,y_train))\n",
    "print('')\n",
    "     \n",
    "print('Testing Accuracy is:',model.score(x_test,y_test))\n",
    "print('')\n",
    "\n",
    "## Precision\n",
    "print('Precision of the model is :',metrics.precision_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##Recall \n",
    "print('Recall of the model is:',metrics.recall_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##F1 score \n",
    "print('The F1 score is:',metrics.f1_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##ROC Auc score \n",
    "print('The ROC auc score is :',metrics.roc_auc_score(y_test,y_predict))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionmatrix=metrics.confusion_matrix(y_test,y_predict)\n",
    "print('The Confusion Matrix is displayed below :')\n",
    "print('')\n",
    "\n",
    "print(confusionmatrix)\n",
    "print('')\n",
    "\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test,y_predict)\n",
    "sns.heatmap(cm,annot=True,  fmt='.2f', xticklabels = [0,1] , yticklabels = [0,1])\n",
    "plt.ylabel('Observed')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true positives show slight improvement .We will hence stick to the parameters used and then use 'class_weight'= 'balanced' as our data seems to be highly imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Treating the imbalance in the data by tweaking the class_weight parameter ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy\n",
    "model=LogisticRegression(random_state=None,penalty='l2',solver='saga',C=1,class_weight='balanced')\n",
    "model.fit(x_train,y_train)\n",
    "y_predict=model.predict(x_test)\n",
    "\n",
    "print('Training Accuracy is :',model.score(x_train,y_train))\n",
    "print('')\n",
    "     \n",
    "print('Testing Accuracy is:',model.score(x_test,y_test))\n",
    "print('')\n",
    "\n",
    "## Precision\n",
    "print('Precision of the model is :',metrics.precision_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##Recall \n",
    "print('Recall of the model is:',metrics.recall_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##F1 score \n",
    "print('The F1 score is:',metrics.f1_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##ROC Auc score \n",
    "print('The ROC AUC score is :',metrics.roc_auc_score(y_test,y_predict))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_acc=model.score(x_test,y_test)\n",
    "logreg_recall=metrics.recall_score(y_test,y_predict)\n",
    "logreg_f1score=metrics.f1_score(y_test,y_predict)\n",
    "logreg_ROCAUC=metrics.roc_auc_score(y_test,y_predict)\n",
    "logreg_precision=metrics.precision_score(y_test,y_predict)\n",
    "\n",
    "print(logreg_acc)\n",
    "print(logreg_recall)\n",
    "print(logreg_f1score)\n",
    "print(logreg_ROCAUC)\n",
    "print(logreg_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionmatrix=metrics.confusion_matrix(y_test,y_predict)\n",
    "print('The Confusion Matrix is displayed below :')\n",
    "print('')\n",
    "\n",
    "print(confusionmatrix)\n",
    "print('')\n",
    "\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test,y_predict)\n",
    "sns.heatmap(cm,annot=True,  fmt='.2f', xticklabels = [0,1] , yticklabels = [0,1])\n",
    "plt.ylabel('Observed')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC/AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(y_test, model.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing the data has significantly improved the Recall,F1 score and ROC AUC score.We therefore will retain this as our final model for Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Decision Trees - Modeling Steps`\n",
    "\n",
    "1. Build the decision tree with default parameters.\n",
    "2. Since Decision trees are prone to over fitting we check if there’s any over fitting of the data .\n",
    "3. If the model is over fit we prune the tree by defining the depth of the tree\n",
    "4. Check the train and test accuracy scores to see if the model is over fitting.\n",
    "5. Print the metrics - Recall,ROC/AUC score,Accuracy,F1 Score,Precision.\n",
    "6. The data is highly imbalanced ,hence we use class weight balancing to achieve optimal results .\n",
    "7. Print the metrics - Recall,ROC/AUC score,Accuracy,F1 Score,Precision. Print the confusion matrix.Print the ROC/AUC curve.\n",
    "8. Store the model metrics in a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.get_dummies(data2.drop('Target',axis=1),drop_first=True)\n",
    "Y=data2['Target']\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=1)\n",
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0:0.2f}% data is in training set\".format((len(x_train)/len(data2.index)) * 100))\n",
    "print(\"{0:0.2f}% data is in test set\".format((len(x_test)/len(data2.index)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gini=DecisionTreeClassifier(criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gini.fit(x_train,y_train)\n",
    "y_predict=model_gini.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Training accuracy\n",
    "\n",
    "modelgini_score_train=model_gini.score(x_train,y_train)\n",
    "print('Training Accuracy is:',modelgini_score_train)\n",
    "\n",
    "### Testing accuracy\n",
    "\n",
    "modelgini_score=model_gini.score(x_test,y_test)\n",
    "print('Test Accuracy is :',modelgini_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since decision trees are prone to overfitting and clearly we see the training accuracy score much higher than test ,our next step would be to prune the  decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pruned=DecisionTreeClassifier(criterion='gini',max_depth=6)\n",
    "clf_pruned.fit(x_train,y_train)\n",
    "y_predict=clf_pruned.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Training accuracy\n",
    "\n",
    "clf_pruned_score_train=clf_pruned.score(x_train,y_train)\n",
    "print('Training Accuracy is:',clf_pruned_score_train)\n",
    "\n",
    "### Testing accuracy\n",
    "\n",
    "clf_pruned_score_test=clf_pruned.score(x_test,y_test)\n",
    "print('Test Accuracy is :',clf_pruned_score_test)\n",
    "\n",
    "## Precision\n",
    "print('Precision of the model is :',metrics.precision_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##Recall \n",
    "print('Recall of the model is:',metrics.recall_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##F1 score \n",
    "print('The F1 score is:',metrics.f1_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##ROC Auc score \n",
    "print('The ROC auc score is :',metrics.roc_auc_score(y_test,y_predict))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Max depth 6 seems to give us good accuracy for both train and test without overfitting the test data.\n",
    "\n",
    "2. Balancing the model to see how the metrics change after class weight balancing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pruned_bal=DecisionTreeClassifier(criterion='gini',max_depth=6,class_weight='balanced')\n",
    "clf_pruned_bal.fit(x_train,y_train)\n",
    "y_predict=clf_pruned_bal.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Training accuracy\n",
    "\n",
    "clf_pruned_bal_score_train=clf_pruned_bal.score(x_train,y_train)\n",
    "print('Training Accuracy is:',clf_pruned_bal_score_train)\n",
    "\n",
    "### Testing accuracy\n",
    "\n",
    "clf_pruned_bal_score_test=clf_pruned_bal.score(x_test,y_test)\n",
    "print('Test Accuracy is :',clf_pruned_bal_score_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Precision\n",
    "print('Precision of the model is :',metrics.precision_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##Recall \n",
    "print('Recall of the model is:',metrics.recall_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##F1 score \n",
    "print('The F1 score is:',metrics.f1_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##ROC Auc score \n",
    "print('The ROC auc score is :',metrics.roc_auc_score(y_test,y_predict))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pruned_bal_score_test=clf_pruned_bal.score(x_test,y_test)\n",
    "clf_pruned_bal_recall=metrics.recall_score(y_test,y_predict)\n",
    "clf_pruned_bal_f1score=metrics.f1_score(y_test,y_predict)\n",
    "clf_pruned_bal_ROCAUC=metrics.roc_auc_score(y_test,y_predict)\n",
    "clf_pruned_bal_precision=metrics.precision_score(y_test,y_predict)\n",
    "\n",
    "print(clf_pruned_bal_score_test)\n",
    "print(clf_pruned_bal_recall)\n",
    "print(clf_pruned_bal_f1score)\n",
    "print(clf_pruned_bal_ROCAUC)\n",
    "print(clf_pruned_bal_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionmatrix=metrics.confusion_matrix(y_test,y_predict)\n",
    "print('The Confusion Matrix is displayed below :')\n",
    "print('')\n",
    "\n",
    "print(confusionmatrix)\n",
    "print('')\n",
    "\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test,y_predict)\n",
    "sns.heatmap(cm,annot=True,  fmt='.2f', xticklabels = [0,1] , yticklabels = [0,1])\n",
    "plt.ylabel('Observed')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_roc_auc = roc_auc_score(y_test, clf_pruned_bal.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, clf_pruned_bal.predict_proba(x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Decision Tree (area = %0.2f)' % dtree_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance with yellowbrick library\n",
    "\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "viz = ClassificationReport(DecisionTreeClassifier(criterion='gini',max_depth=6,class_weight='balanced'))\n",
    "viz.fit(x_train, y_train)\n",
    "viz.score(x_test, y_test)\n",
    "viz.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(clf_pruned_bal, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('bankdata_pruned.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the Model output in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DF=pd.DataFrame({'Model':['Decision Tree'],'Accuracy':clf_pruned_bal_score_test,'Recall':clf_pruned_bal_recall,'Precision':clf_pruned_bal_precision,'F1 Score':clf_pruned_bal_f1score,'ROC_AUC Score':clf_pruned_bal_ROCAUC})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Inferences`\n",
    "\n",
    "We see form the above that the precision and Accuracy have dropped ,while the Recall,F1 score and the ROC AUC score have significantly improved after the class weight the balancing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Random Forest Model - Modeling Steps`\n",
    "\n",
    "1. Build the Random forest model with default parameters\n",
    "2. Check if the model has over fitted and needs to be tuned to achieve optimal results \n",
    "3. Adjust the hyper parameters ,in this case max depth to see if this changes the results.\n",
    "4. Print the metrics -Recall,ROC/AUC score,Accuracy,F1 Score,Precision.\n",
    "5. Since the data is highly imbalanced ,try class weight balancing on the model to see if this improves the metrics of the model \n",
    "6. If it improves the accuracy, print the metrics again.\n",
    "7. Adjust other hyper parameters to see if there’s improvement in the model results.If yes, print the model results .\n",
    "8. Store the model results into the data frame by concatenating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.get_dummies(data2.drop('Target',axis=1),drop_first=True)\n",
    "Y=data2['Target']\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=1)\n",
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfcl=RandomForestClassifier()\n",
    "\n",
    "## Fit the model on the training set \n",
    "rfcl_model=rfcl.fit(x_train, y_train)\n",
    "\n",
    "## Predicting on test set\n",
    "y_predict=rfcl.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcl.score(x_train,y_train)\n",
    "print(rfcl.score(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcl.score(x_test,y_test)\n",
    "print(rfcl.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the test data is overfitting and requires some tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcl.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcl_dep=RandomForestClassifier(max_depth=10)\n",
    "\n",
    "## Fit the model on the training set \n",
    "rfcl_model_1=rfcl_dep.fit(x_train, y_train)\n",
    "\n",
    "## Predicting on test set\n",
    "y_predict=rfcl_dep.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcl_dep.score(x_train,y_train)\n",
    "print(rfcl_dep.score(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcl_dep.score(x_test,y_test)\n",
    "print(rfcl_dep.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy\n",
    "\n",
    "print('Training Accuracy is :',rfcl_dep.score(x_train,y_train))\n",
    "print('')\n",
    "     \n",
    "print('Testing Accuracy is:',rfcl_dep.score(x_test,y_test))\n",
    "print('')\n",
    "\n",
    "## Precision\n",
    "print('Precision of the model is :',metrics.precision_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##Recall \n",
    "print('Recall of the model is:',metrics.recall_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##F1 score \n",
    "print('The F1 score is:',metrics.f1_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##ROC Auc score \n",
    "print('The ROC AUC score is :',metrics.roc_auc_score(y_test,y_predict))\n",
    "print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcl_bal=RandomForestClassifier(max_depth=10,class_weight='balanced')\n",
    "\n",
    "## Fit the model on the training set \n",
    "rfcl_model_2=rfcl_bal.fit(x_train, y_train)\n",
    "\n",
    "## Predicting on test set\n",
    "y_predict=rfcl_bal.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy\n",
    "\n",
    "print('Training Accuracy is :',rfcl_bal.score(x_train,y_train))\n",
    "print('')\n",
    "     \n",
    "print('Testing Accuracy is:',rfcl_bal.score(x_test,y_test))\n",
    "print('')\n",
    "\n",
    "## Precision\n",
    "print('Precision of the model is :',metrics.precision_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##Recall \n",
    "print('Recall of the model is:',metrics.recall_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##F1 score \n",
    "print('The F1 score is:',metrics.f1_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##ROC Auc score \n",
    "print('The ROC AUC score is :',metrics.roc_auc_score(y_test,y_predict))\n",
    "print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcl_est=RandomForestClassifier(max_depth=10,class_weight='balanced',n_estimators=1000,min_samples_leaf=6)\n",
    "\n",
    "## Fit the model on the training set \n",
    "rfcl_model_3=rfcl_est.fit(x_train, y_train)\n",
    "\n",
    "## Predicting on test set\n",
    "y_predict=rfcl_est.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy\n",
    "\n",
    "print('Training Accuracy is :',rfcl_est.score(x_train,y_train))\n",
    "print('')\n",
    "     \n",
    "print('Testing Accuracy is:',rfcl_est.score(x_test,y_test))\n",
    "print('')\n",
    "\n",
    "## Precision\n",
    "print('Precision of the model is :',metrics.precision_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##Recall \n",
    "print('Recall of the model is:',metrics.recall_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##F1 score \n",
    "print('The F1 score is:',metrics.f1_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##ROC Auc score \n",
    "print('The ROC AUC score is :',metrics.roc_auc_score(y_test,y_predict))\n",
    "print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix=metrics.confusion_matrix(y_test,y_predict)\n",
    "print('The confusion matrix is printed below')\n",
    "print('')\n",
    "\n",
    "print(confusion_matrix)\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test,y_predict)\n",
    "sns.heatmap(cm,annot=True,  fmt='.2f', xticklabels = [0,1] , yticklabels = [0,1])\n",
    "plt.ylabel('Observed')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tuning using leaf depth to see if it improves the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score=[]\n",
    "test_score=[]\n",
    "recall=[]\n",
    "f1score=[]\n",
    "precision=[]\n",
    "min_samples_leaf=[1,2,3,4,5,6]\n",
    "\n",
    "for i in min_samples_leaf:\n",
    "    model=RandomForestClassifier(max_depth=10,class_weight='balanced',n_estimators=1000,min_samples_leaf=i)\n",
    "    model.fit(x_train,y_train)\n",
    "    y_predict=model.predict(x_test)\n",
    "    train_score.append(round(model.score(x_train,y_train),2))\n",
    "    test_score.append(round(model.score(x_test,y_test),2))\n",
    "    recall.append(round(metrics.recall_score(y_test,y_predict),2))\n",
    "    f1score.append(round(metrics.f1_score(y_test,y_predict),2))\n",
    "    precision.append(round(metrics.precision_score(y_test,y_predict),2))\n",
    "    \n",
    "print(min_samples_leaf)\n",
    "print()\n",
    "print(train_score)\n",
    "print('Test Accuracy')\n",
    "print(test_score)\n",
    "print('Recall')\n",
    "print(recall)\n",
    "print('f1score')\n",
    "print(f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select min_samples_leaf=6 as the recall is much better than the remainder of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcl_acc=rfcl_est.score(x_test,y_test)\n",
    "rfcl_recall=metrics.recall_score(y_test,y_predict)\n",
    "rfcl_f1score=metrics.f1_score(y_test,y_predict)\n",
    "rfcl_ROCAUC=metrics.roc_auc_score(y_test,y_predict)\n",
    "rfcl_precision=metrics.precision_score(y_test,y_predict)\n",
    "\n",
    "print(rfcl_acc)\n",
    "print(rfcl_recall)\n",
    "print(rfcl_f1score)\n",
    "print(rfcl_ROCAUC)\n",
    "print(rfcl_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempResultsDf = pd.DataFrame({'Model':['Random Forest'],'Accuracy':rfcl_acc,'Recall':rfcl_recall,'Precision':rfcl_precision,'F1 Score':rfcl_f1score,'ROC_AUC Score':rfcl_ROCAUC})\n",
    "results_DF=pd.concat([results_DF,tempResultsDf])\n",
    "results_DF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Adaboost Ensemble algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AdaBoost Ensemble algorithm - Modeling Steps` \n",
    "\n",
    "1. Build the Ada boost classifier algorithm with pre set parameters\n",
    "2. Check if the model overfits .\n",
    "3. If it doesn’t print the metrics \n",
    "4. Visualise  and print the confusion matrix\n",
    "5. Add the Ada boost model results to the data frame by concatenating to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abcl=AdaBoostClassifier(n_estimators=100,random_state=22)\n",
    "abcl.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_predict=abcl.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy\n",
    "\n",
    "print('Training Accuracy is :',abcl.score(x_train,y_train))\n",
    "print('')\n",
    "     \n",
    "print('Testing Accuracy is:',abcl.score(x_test,y_test))\n",
    "print('')\n",
    "\n",
    "## Precision\n",
    "print('Precision of the model is :',metrics.precision_score(y_test,ab_predict))\n",
    "print('')\n",
    "\n",
    "##Recall \n",
    "print('Recall of the model is:',metrics.recall_score(y_test,ab_predict))\n",
    "print('')\n",
    "\n",
    "##F1 score \n",
    "print('The F1 score is:',metrics.f1_score(y_test,ab_predict))\n",
    "print('')\n",
    "\n",
    "##ROC Auc score \n",
    "print('The ROC AUC score is :',metrics.roc_auc_score(y_test,ab_predict))\n",
    "print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcl_acc=abcl.score(x_test,y_test)\n",
    "abcl_recall=metrics.recall_score(y_test,ab_predict)\n",
    "abcl_f1score=metrics.f1_score(y_test,ab_predict)\n",
    "abcl_ROCAUC=metrics.roc_auc_score(y_test,ab_predict)\n",
    "abcl_precision=metrics.precision_score(y_test,ab_predict)\n",
    "\n",
    "print(abcl_acc)\n",
    "print(abcl_recall)\n",
    "print(abcl_f1score)\n",
    "print(abcl_ROCAUC)\n",
    "print(abcl_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance with yellowbrick library\n",
    "viz = ClassificationReport(AdaBoostClassifier(n_estimators=100,random_state=22))\n",
    "viz.fit(x_train, y_train)\n",
    "viz.score(x_test, y_test)\n",
    "viz.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix=metrics.confusion_matrix(y_test,ab_predict)\n",
    "print('The confusion matrix is printed below')\n",
    "print('')\n",
    "\n",
    "print(confusion_matrix)\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test,ab_predict)\n",
    "sns.heatmap(cm,annot=True,  fmt='.2f', xticklabels = [0,1] , yticklabels = [0,1])\n",
    "plt.ylabel('Observed')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,ab_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test,ab_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempResultsDf = pd.DataFrame({'Model':['AdaBoost Classifier'],'Accuracy':abcl_acc,'Recall':abcl_recall,'Precision':abcl_precision,'F1 Score':abcl_f1score,'ROC_AUC Score':abcl_ROCAUC})\n",
    "\n",
    "results_DF=pd.concat([results_DF,tempResultsDf])\n",
    "\n",
    "results_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bagging Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Bagging Classifier Algorithm - Modeling Steps` \n",
    "\n",
    "1. Build the Bagging classifier algorithm with pre set parameters\n",
    "2. Check if the model overfits .\n",
    "3. If it doesn’t print the metrics \n",
    "4. Visualise  and print the confusion matrix\n",
    "5. Add the Bagging Classifier Algorithm results to the data frame by concatenating to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bgcl=BaggingClassifier(n_estimators=100, max_samples= .7, bootstrap=True, oob_score=True, random_state=22)\n",
    "bgcl=bgcl.fit(x_train,y_train)\n",
    "y_predict=bgcl.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Training accuracy\n",
    "\n",
    "bgcl_score_train=bgcl.score(x_train,y_train)\n",
    "print('Training Accuracy is:',bgcl_score_train)\n",
    "\n",
    "### Testing accuracy\n",
    "\n",
    "bgcl_score_test=bgcl.score(x_test,y_test)\n",
    "print('Test Accuracy is :',bgcl_score_test)\n",
    "\n",
    "## Precision\n",
    "print('Precision of the model is :',metrics.precision_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##Recall \n",
    "print('Recall of the model is:',metrics.recall_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##F1 score \n",
    "print('The F1 score is:',metrics.f1_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##ROC Auc score \n",
    "print('The ROC auc score is :',metrics.roc_auc_score(y_test,y_predict))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix=metrics.confusion_matrix(y_test,y_predict)\n",
    "print('The confusion matrix is printed below')\n",
    "print('')\n",
    "\n",
    "print(confusion_matrix)\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test,y_predict)\n",
    "sns.heatmap(cm,annot=True,  fmt='.2f', xticklabels = [0,1] , yticklabels = [0,1])\n",
    "plt.ylabel('Observed')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgcl_score=bgcl.score(x_test,y_test)\n",
    "bgcl_recall=metrics.recall_score(y_test,y_predict)\n",
    "bgcl_f1score=metrics.f1_score(y_test,y_predict)\n",
    "bgcl_ROCAUC=metrics.roc_auc_score(y_test,y_predict)\n",
    "bgcl_precision=metrics.precision_score(y_test,y_predict)\n",
    "\n",
    "print(bgcl_score)\n",
    "print(bgcl_recall)\n",
    "print(bgcl_f1score)\n",
    "print(bgcl_ROCAUC)\n",
    "print(bgcl_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_DF=pd.DataFrame({'Model':['Bagging Classifier'],'Accuracy':bgcl_score,'Recall':bgcl_recall,'Precision':bgcl_precision,'F1 Score':bgcl_f1score,'ROC_AUC Score':bgcl_ROCAUC})\n",
    "\n",
    "results_DF=pd.concat([results_DF,temporary_DF])\n",
    "\n",
    "results_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance with yellowbrick library\n",
    "viz = ClassificationReport(BaggingClassifier(n_estimators=100, max_samples= .7, bootstrap=True, oob_score=True, random_state=22))\n",
    "viz.fit(x_train, y_train)\n",
    "viz.score(x_test, y_test)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boost Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Gradient boost classifier - Modeling steps`\n",
    "\n",
    "1. Build the Gradient boost classifier algorithm with pre set parameters\n",
    "2. Check if the model overfits .\n",
    "3. If it doesn’t print the metrics \n",
    "4. Visualise  and print the confusion matrix\n",
    "5. Add the Bagging Classifier Algorithm results to the data frame by concatenating to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbcl=GradientBoostingClassifier(n_estimators = 50, learning_rate = .1, random_state=22)\n",
    "gbcl=gbcl.fit(x_train,y_train)\n",
    "y_predict=gbcl.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Training accuracy\n",
    "\n",
    "gbcl_score_train=gbcl.score(x_train,y_train)\n",
    "print('Training Accuracy is:',bgcl_score_train)\n",
    "\n",
    "### Testing accuracy\n",
    "\n",
    "gbcl_score_test=gbcl.score(x_test,y_test)\n",
    "print('Test Accuracy is :',gbcl_score_test)\n",
    "\n",
    "## Precision\n",
    "print('Precision of the model is :',metrics.precision_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##Recall \n",
    "print('Recall of the model is:',metrics.recall_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##F1 score \n",
    "print('The F1 score is:',metrics.f1_score(y_test,y_predict))\n",
    "print('')\n",
    "\n",
    "##ROC Auc score \n",
    "print('The ROC auc score is :',metrics.roc_auc_score(y_test,y_predict))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix=metrics.confusion_matrix(y_test,y_predict)\n",
    "print('The confusion matrix is printed below')\n",
    "print('')\n",
    "\n",
    "print(confusion_matrix)\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test,y_predict)\n",
    "sns.heatmap(cm,annot=True,  fmt='.2f', xticklabels = [0,1] , yticklabels = [0,1])\n",
    "plt.ylabel('Observed')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model overfits and needs futher hyperparameter tuning .Tuning min_samples_leaf ,min_samples_split,max_depth has not changed the accuracy.There is also no option to class balance in this classifier which may contribute to the difference in the model performance .\n",
    "\n",
    "Hence we will go ahead and append this model result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcl_score=gbcl.score(x_test,y_test)\n",
    "gbcl_recall=metrics.recall_score(y_test,y_predict)\n",
    "gbcl_f1score=metrics.f1_score(y_test,y_predict)\n",
    "gbcl_ROCAUC=metrics.roc_auc_score(y_test,y_predict)\n",
    "gbcl_precision=metrics.precision_score(y_test,y_predict)\n",
    "\n",
    "print(gbcl_score)\n",
    "print(gbcl_recall)\n",
    "print(gbcl_f1score)\n",
    "print(gbcl_ROCAUC)\n",
    "print(gbcl_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_DF=pd.DataFrame({'Model':['Gradient Boost Algorithm'],'Accuracy':gbcl_score,'Recall':gbcl_recall,'Precision':gbcl_precision,'F1 Score':gbcl_f1score,'ROC_AUC Score':gbcl_ROCAUC})\n",
    "\n",
    "results_DF=pd.concat([results_DF,temporary_DF])\n",
    "\n",
    "results_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appending the Logistic regression model results too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_DF=pd.DataFrame({'Model':['Logistic Regression'],'Accuracy':logreg_acc,'Recall':logreg_recall,'Precision':logreg_precision,'F1 Score':logreg_f1score,'ROC_AUC Score':logreg_ROCAUC})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DF=pd.concat([results_DF,temporary_DF])\n",
    "\n",
    "results_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_Final=results_DF\n",
    "results_Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`Business Insights`\n",
    "\n",
    "True Negative (observed=0,predicted=0)\n",
    "\n",
    "Predicted that the customer would not subscribe and they actually do not.\n",
    "\n",
    "False Positive (observed=0,predicted=1)\n",
    "\n",
    "Predicted that the customer would subscribe while the customer did not.\n",
    "\n",
    "True Negative (observed=0,predicted=0)\n",
    "\n",
    "Predicted that the customer would not subscribe and the customer did not.\n",
    "\n",
    "False Negative(observed=1,predicted=0)\n",
    "\n",
    "Predicted the customer would not subscribe when the customer did.\n",
    "\n",
    "`From the points above we know that we should be focusing on`\n",
    "\n",
    "Low False Negatives as False negatives would mean missed opportunity for the bank in predicting clients who could convert as fixed term subscribers.\n",
    "\n",
    "High score of True positives which would mean the prediction on the fixed term subscribers would be accurate.\n",
    "\n",
    "False Positives in this case could be relatively harmless as this would not mean that the bank would lose money.\n",
    "\n",
    "\n",
    "`Conclusions` \n",
    "\n",
    "1. Random Forest gives the best balance of Recall,ROC AUC curve with decent values for Accuracy,F1 score & Precision.We see from each of the Confusion Matrix of the models that the False negatives are the least for Random Forest and Descision Tree classifiers\n",
    "\n",
    "2. Although Decision tree gives us a higher recall value ,we also take into account the other parameters to contribute to the overalls.\n",
    "\n",
    "3. It is important to note that the accuracy and precision have gone down a little bit as compared to the other models but these have gone down at the stake of Recall.Also we see a reassuring high ROC /AUC score for Random Forest as compared to all other models.\n",
    "\n",
    "\n",
    "4. Our focus area is low False Negatives and high True positives .Therefore we could conclude that given the metrics we defined ,that RandomForest Classifier is the best model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`N.B`: As per https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
    "\n",
    "duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "\n",
    "***Dropping 'Duration' from the dataframe before modeling as per the text in the link did not improve any of the modeling parameters and on the contrary had got the recall and accuracy scores down drastically,since there's not mcuh clarity in the problem statement document ,this problem was parked to analyse the complete dataset witout dropping duration(and only transforming it).***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
