{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Objective \n",
    "\n",
    "Given a Bank customer, build a neural network-based classifier that can determine whether they will leave or not in the next 6 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6hGEnTHGBme",
    "outputId": "b2265269-b967-4955-9d77-7dae28169e93"
   },
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5Ln1gFKGF96",
    "outputId": "e0258072-2f74-4d88-c520-fa9c765236ab"
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "or4j8qPgc9QV"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# For missing values\n",
    "import missingno as msno\n",
    "\n",
    "# Ignore warnings \n",
    "import warnings\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sklearn libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc,classification_report\n",
    "\n",
    "\n",
    "# Tensorflow libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras import optimizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i2YDxwxJnGi"
   },
   "source": [
    "###### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l8b2pqQOGTmd"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "BLBxZhvPGgaR",
    "outputId": "ae92360d-d549-4760-9cc4-56cda9942387"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcFYqTbkHBqk",
    "outputId": "6fb6bbaf-7572-4012-d0e9-9d9e52d72404"
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Drop the unwanted variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GXv5cvdHRIi"
   },
   "outputs": [],
   "source": [
    "data.drop(['RowNumber','CustomerId','Surname'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87auAAttHws4",
    "outputId": "eebdd781-09e0-421b-e984-719dd5680b06"
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drC6mb__J1J8"
   },
   "source": [
    "##### Basic checks on the data before getting it ready for analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZu1LETLJ6-c"
   },
   "outputs": [],
   "source": [
    "def basic_checks(df):\n",
    "    \n",
    "    print('='*50)\n",
    "    print('Shape of the dataframe is: \\n',df.shape)\n",
    "    print('='*50)\n",
    "    print('Basic stats for the data: \\n',df.describe())\n",
    "    print('='*50)\n",
    "    print('Data type and info :')\n",
    "    print(df.info())\n",
    "    print('='*50)\n",
    "    print('Missing value information : \\n',df.isnull().any())\n",
    "    print('='*50)\n",
    "    print('Sum of missing values if any : \\n',df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbyJMpPhKBu3",
    "outputId": "60bd10a0-13fb-4fbc-c8a5-2af269efe3a4"
   },
   "outputs": [],
   "source": [
    "basic_checks(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cwSsV_1KhYZ"
   },
   "source": [
    "###### Missing values matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "id": "pXTsUwXjKFLo",
    "outputId": "96167199-7608-497a-cedf-6538b235909e"
   },
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Awl4QFvK5gV"
   },
   "source": [
    "No missing values in the dataset,in any of the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENj7RfoqLDgx"
   },
   "source": [
    "##### Plotting correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "FPmOvzsYLMo8",
    "outputId": "0c5525de-dc0c-4945-a3b3-58d5518abc1d"
   },
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "id": "WZpoHM5NLOxu",
    "outputId": "48c0b1ef-f8c9-4e46-9942-18656bdbbbea"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "sns.heatmap(data.corr(),\n",
    "            annot=True,\n",
    "            linewidths=.5,\n",
    "            center=0,\n",
    "            cbar=False,\n",
    "            cmap=\"YlGnBu\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vb-Nbk5LmSV"
   },
   "source": [
    "                    ####################### EDA PART 1#############################\n",
    "\n",
    "`EDA PART 1`\n",
    "\n",
    "1.There float,int and object data types in the dataset\n",
    "\n",
    "2.Row number,customerID and surname are not required for the analysis and hence we will drop the columns\n",
    "\n",
    "3.There are 10000 records and 11 columns in the dataset\n",
    "\n",
    "4.Average age in the dataset is 38,average tenure is 5.01 ,the data in both these columns is less skewed.Average balance is 76485.\n",
    "\n",
    "5.Estimated salary is at 100090 average value and the data is not skewed.\n",
    "\n",
    "6.There is no missing values in the dataset.\n",
    "\n",
    "7.The target variable here is ‘Exited’ since we would like to see and predict the probability of the customer exiting\n",
    "\n",
    "8.There’s no strong correlation between the target variables and the dependant variables in the dataset.\n",
    "\n",
    "9.Exited and age show some correlation of 0.2.Number of products and balance seems to be slightly negatively correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWmDwGhgPUNh"
   },
   "outputs": [],
   "source": [
    "def catplot(variable):\n",
    "    fig=plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.countplot(x=variable,data=data)\n",
    "    plt.subplot(1,2,2)\n",
    "    sns.countplot(x=variable, hue='Exited', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "7im5HSsRPWAI",
    "outputId": "36995c24-9835-4dd8-ea0f-9c0cf43b69de"
   },
   "outputs": [],
   "source": [
    "catplot(data['Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Geography']=='France'].shape[0]/data['Geography'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Geography']=='Spain'].shape[0]/data['Geography'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Geography']=='Germany'].shape[0]/data['Geography'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['Geography']=='France')&(data['Exited']==1)].shape[0]/data['Geography'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['Geography']=='Spain')&(data['Exited']==1)].shape[0]/data['Geography'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['Geography']=='Germany')&(data['Exited']==1)].shape[0]/data['Geography'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "w8z-5TwHPeam",
    "outputId": "bcb1a368-ae5c-494f-b370-854eda077741"
   },
   "outputs": [],
   "source": [
    "catplot(data['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Gender']=='Male'].shape[0]/data['Gender'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Gender']=='Female'].shape[0]/data['Gender'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['Gender']=='Male')&(data['Exited']==1)].shape[0]/data['Gender'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['Gender']=='Female')&(data['Exited']==1)].shape[0]/data['Gender'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "kUXC4X8FP9tv",
    "outputId": "3e4f6cf6-afb9-4970-9beb-97eb935d43ff"
   },
   "outputs": [],
   "source": [
    "catplot(data['Tenure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYPdZZ0yt9iw"
   },
   "outputs": [],
   "source": [
    "def tenure_cat(x):\n",
    "    if(x>0)&(x<=2):\n",
    "        return 0\n",
    "    else:\n",
    "        if(x>2)&(x<=4):\n",
    "            return 1\n",
    "        else:\n",
    "            if(x>4)&(x<=6):\n",
    "                return 2\n",
    "            else:\n",
    "                  if(x>6)&(x<=8):\n",
    "                      return 3\n",
    "                  else:\n",
    "                      if(x>8)&(x<=10):\n",
    "                          return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBR5NbCuxK52"
   },
   "outputs": [],
   "source": [
    "data['Tenure_cat']=data['Tenure'].apply(tenure_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catplot(data['Tenure_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Tenure_cat']==0].shape[0]/data['Tenure_cat'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Tenure_cat']==1].shape[0]/data['Tenure_cat'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Tenure_cat']==2].shape[0]/data['Tenure_cat'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Tenure_cat']==3].shape[0]/data['Tenure_cat'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Tenure_cat']==4].shape[0]/data['Tenure_cat'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['Tenure_cat']==0)&(data['Exited']==1)].shape[0]/data[data['Exited']==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['Tenure_cat']==1)&(data['Exited']==1)].shape[0]/data[data['Exited']==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['Tenure_cat']==2)&(data['Exited']==1)].shape[0]/data[data['Exited']==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['Tenure_cat']==3)&(data['Exited']==1)].shape[0]/data[data['Exited']==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['Tenure_cat']==3)&(data['Exited']==1)].shape[0]/data[data['Exited']==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "NkpftmPPSCT0",
    "outputId": "e5310726-9560-4bce-877d-44e77e1e39c5"
   },
   "outputs": [],
   "source": [
    "catplot(data['NumOfProducts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['NumOfProducts']==1].shape[0]/data['NumOfProducts'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['NumOfProducts']==2].shape[0]/data['NumOfProducts'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['NumOfProducts']==3].shape[0]/data['NumOfProducts'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['NumOfProducts']==4].shape[0]/data['NumOfProducts'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['NumOfProducts']==1)&(data['Exited']==1)].shape[0]/data[data['Exited']==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['NumOfProducts']==2)&(data['Exited']==1)].shape[0]/data[data['Exited']==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['NumOfProducts']==3)&(data['Exited']==1)].shape[0]/data[data['Exited']==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['NumOfProducts']==4)&(data['Exited']==1)].shape[0]/data[data['Exited']==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "QHGO-gOySLPG",
    "outputId": "0b5caac2-723c-4f90-e447-872c8e78155c"
   },
   "outputs": [],
   "source": [
    "catplot(data['HasCrCard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['HasCrCard']==0].shape[0]/data['HasCrCard'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['HasCrCard']==1].shape[0]/data['HasCrCard'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['HasCrCard']==0)&(data['Exited']==1)].shape[0]/data[data['Exited']==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['HasCrCard']==1)&(data['Exited']==1)].shape[0]/data[data['Exited']==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "5TxhcBMvSXpq",
    "outputId": "a2e20c23-58f4-421c-f967-1048e31f2651"
   },
   "outputs": [],
   "source": [
    "catplot(data['IsActiveMember'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['IsActiveMember']==0].shape[0]/data['IsActiveMember'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['IsActiveMember']==1].shape[0]/data['IsActiveMember'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['IsActiveMember']==0)&(data['Exited']==1)].shape[0]/data[data['Exited']==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['IsActiveMember']==1)&(data['Exited']==1)].shape[0]/data[data['Exited']==1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOtWCbS1RQz1"
   },
   "source": [
    "### Continuous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEfRPQcxRWeG"
   },
   "outputs": [],
   "source": [
    "def plots(variable):\n",
    "    fig=plt.figure(figsize=(10,5))\n",
    "    plt.subplot(131)\n",
    "    sns.distplot(data[variable])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.subplot(132)\n",
    "    sns.boxplot(x=data[variable])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.subplot(133)\n",
    "    sns.boxplot(x=data['Exited'],y=data[variable])\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "F03wVKxERgTw",
    "outputId": "8cc9a0b5-5fd6-4e0e-a36b-d4aa9d8725f9"
   },
   "outputs": [],
   "source": [
    "plots('CreditScore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "WWDPbCUVRv9q",
    "outputId": "a57a8af5-1be0-4fbe-e963-d6c185c9587d"
   },
   "outputs": [],
   "source": [
    "plots('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "6jia_iAaR0Xl",
    "outputId": "24b4a8ce-7eb2-47ae-fa2c-59b9140aa384"
   },
   "outputs": [],
   "source": [
    "plots('Balance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "0PhsoJUfR8L1",
    "outputId": "1b32a0b3-afc6-4443-e312-22ed7b24a7db"
   },
   "outputs": [],
   "source": [
    "plots('EstimatedSalary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dependent variable distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Exited']==1].shape[0]/data['Exited'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Exited']==0].shape[0]/data['Exited'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['Exited']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['Exited']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ EDA PART 2 #####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### `EDA - Part 2`\n",
    "\n",
    "`Categorical plots`\n",
    "\n",
    "1. Georgraphy - Maximum number of exits are from France,Germany (at 0.08%)followed by Spain (0.04%).There are also highest number of people that do not exit in France it could be attributed to high number of overalls for France(50% of the data).\n",
    "2. Gender - There is 54.5% is Male and 45.4 % are Female ,the % of exits are treated in females than in Males . 11.3% vs 8.9% in males.\n",
    "3. Tenure - There’s an even distribution of data amongst tenures that are bucketed between 0-2,2-4 ,…8-10 years .The % of exits is also fairly even amongst different tenures.\n",
    "4. 50.8 % of the customers have 1 bank affiliated bank product ,followed by 45% and a minimal 3% for products 3&4 \n",
    "5. 70% of the customers that exited have 1 bank affiliated product and over 30% have more than 2 products in their bank account \n",
    "6. Has credit card. - 70 % of the customers have credit cards \n",
    "7. There’s an even distribution between active members and not active members .\n",
    "8.  Non active members that have exited the bank are 63% \n",
    "\n",
    "`Continuous plots` \n",
    "\n",
    "Credit score \n",
    "1. The distribution of credit score is close to normal and there are few outliers as we see in the boxplot\n",
    "2. Median credit score is above 625 for the overall data , for those that exited the bank the credit score distribution is similar to that which haven’t exited the bank ,there are a few outliers in the customers that have exited the bank.\n",
    "\n",
    "Age \n",
    "1. Age is right skewed data ,there are few outliers in the Age variable.\n",
    "2. There are a few outliers in the customers that have not exited the bank.\n",
    "\n",
    "Balance \n",
    "1. The distribution of Balance variable is sinusoidal and median value for balance is at 100000,for those that exited the bank the median value is slightly higher than 100000\n",
    "\n",
    "Estimated Salary\n",
    "1. The distribution of Estimated salary is somewhat normal ,with estimated salary median value at close to 100000 for both exited and non exited parties .\n",
    "\n",
    "`Dependent variable distribution` \n",
    "\n",
    "1. There’s class imbalance in the distribution of the Exited customers and the non exited customers 80% vs 20% ,those that exited.\n",
    "2. The credit scores of those that have exited the bank is slightly higher than the one’s that did not exit \n",
    "3. Those that exited the balance and estimated salary is higher than the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Preprocessing the data #####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing the data \n",
    "\n",
    "`Preprocessing the data` \n",
    "\n",
    "1. Drop the unnecessary columns \n",
    "2. Apply One hot encoding on  the categorical variables ,gender and geography\n",
    "3. Check the datatypes of the variables and see if any change in datatype is required\n",
    "\n",
    "`Train Test Split` \n",
    "\n",
    "1. Identify the target and feature variables . X will have all feature variables and Y will have ‘Exited’ as the target variable  as we want to predict the customer exit from the bank.\n",
    "2. We will the split the data into Train,Test data from the 10000  records as 80/20.From the Test we will split 50 % to validation afterward\n",
    "\n",
    "`Scaling the variables` \n",
    "\n",
    "1. We will scale the variables to bring them all on one scale using Standard scalar \n",
    "2. We repeat this on Training,Testing and Validation datasets\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "yhfIlyc70Q8p"
   },
   "source": [
    "data['HasCrCard']=data['HasCrCard'].astype(str)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "eZieUj-D0ZsV"
   },
   "source": [
    "data['IsActiveMember']=data['IsActiveMember'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7-sTrRM0stw"
   },
   "outputs": [],
   "source": [
    "#data['Tenure_cat']=data['Tenure_cat'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AAiftZm90MvD",
    "outputId": "1db3c4ed-00ce-4d38-bf26-adec755a3ae6"
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJuvm-WV06jq"
   },
   "outputs": [],
   "source": [
    "data.drop(['Tenure_cat'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xEu1ZSd1Bi2"
   },
   "outputs": [],
   "source": [
    "data1=pd.get_dummies(data,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "Bhlenxkz2ZBr",
    "outputId": "d9f39d22-7b60-4af4-d1ff-3f4b07084a24"
   },
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJWwY4qEeVsS"
   },
   "source": [
    "##### Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uk071lVUeZEt"
   },
   "outputs": [],
   "source": [
    "x_data = data1.loc[:,data1.columns!='Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVPP-DrUefg1"
   },
   "outputs": [],
   "source": [
    "y_data = data1.loc[:,data1.columns=='Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "eqLnPa2Ieyma",
    "outputId": "25edb732-a0e6-4e94-8218-2cad0040aed2"
   },
   "outputs": [],
   "source": [
    "x_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DhPh2qwifSQB",
    "outputId": "75beea5c-5364-427d-d770-ac85d3b59b6d"
   },
   "outputs": [],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08cYF_q2e0fp",
    "outputId": "da8ac29e-74f8-494c-f293-1058762da702"
   },
   "outputs": [],
   "source": [
    "y_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvQBUCclfEt0",
    "outputId": "6a17a57b-2f32-4f3f-a896-0020246becc2"
   },
   "outputs": [],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-G6asnafatD"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ElgC8IhzWKW"
   },
   "outputs": [],
   "source": [
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size = 0.5, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE - Data Imbalance "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Data pre-processing - Class Balancing and Scaling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Using the SMOTE techinue (Over Sampling) and then run model \n",
    "smt = SMOTE(random_state = 42)\n",
    "x_train, y_train = smt.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecW3SufhzJS9",
    "outputId": "c1460226-bdde-458e-acb3-3e13d5d988bf"
   },
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "sc.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FpaqepEE0XVL"
   },
   "outputs": [],
   "source": [
    "x_train_std=sc.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pp3c-eXo0dCq"
   },
   "outputs": [],
   "source": [
    "x_val_std=sc.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvHAL0Dr0lNx"
   },
   "outputs": [],
   "source": [
    "x_test_std=sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-nDhBZlflSJ"
   },
   "outputs": [],
   "source": [
    "##x_train=preprocessing.normalize(x_train) # Understand why we do this ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "wlsPPNFkCEoq",
    "outputId": "43f44982-f188-4442-d299-55b5b940581c"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Building & Architechture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`Model set up`\n",
    "\n",
    "1. Construct a function defining the model architecture - a)define the epochsb)batch size c)number of neurons d) activation function and e)optimisers f)learning rate set \n",
    "2. define the model summary\n",
    "3. Compile the model \n",
    "4. Get an object of the above function \n",
    "5. Train the model using x train,y train  and pass the test data as validation data\n",
    "6. Print the charts showing the accuracy and loss for both training and validation data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling using Accuracy for testing and validation datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51RkGgQqCYum"
   },
   "outputs": [],
   "source": [
    "epoks=200\n",
    "neurons=[64,32,1]\n",
    "activation=['tanh','sigmoid']\n",
    "batch_size=[10,20,30]\n",
    "learning_rate=0.0001\n",
    "optimizer=[optimizers.Adam(learning_rate=learning_rate),\n",
    "           optimizers.SGD(learning_rate=learning_rate),\n",
    "           optimizers.RMSprop(learning_rate=learning_rate)]\n",
    "\n",
    "def dnn_model():\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Dense(neurons[0], input_dim=x_train.shape[1],activation = activation[0]))\n",
    "    model.add(Dense(neurons[1], activation = activation[0]))\n",
    "    model.add(Dense(neurons[2], activation = activation[1]))\n",
    "\n",
    "    model.compile(optimizer=optimizer[0],loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, Callback, History, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=dnn_model()\n",
    "\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint('best_model.h5', \n",
    "                                     monitor='val_loss', \n",
    "                                     verbose=0, \n",
    "                                     save_best_only=True, \n",
    "                                     save_freq='epoch')\n",
    "\n",
    "history = model.fit(x_train_std,y_train, \n",
    "                    epochs=200, \n",
    "                    batch_size=20,\n",
    "                    validation_data=(x_val_std,y_val),\n",
    "                    callbacks=[model_checkpoint_callback]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking Model Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "neqrcEtdvGdb",
    "outputId": "ca0dc199-fb3c-4398-f277-dc7b0fe14e3f"
   },
   "outputs": [],
   "source": [
    "acc      = history.history[     'accuracy' ]\n",
    "val_acc  = history.history[ 'val_accuracy' ]\n",
    "loss     = history.history[    'loss' ]\n",
    "val_loss = history.history['val_loss' ]\n",
    "\n",
    "epochs   = range(len(acc)) # Get number of epochs\n",
    "\n",
    "\n",
    "plt.plot  ( epochs,     acc ,label='training')\n",
    "plt.plot  ( epochs, val_acc,label='validation' )\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot  ( epochs,     loss , label='training')\n",
    "plt.plot  ( epochs, val_loss , label='validation')\n",
    "plt.title ('Training and validation loss'   )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the probabilities of a customer exiting the bank >0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=model.predict(x_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the probabilities into T/F or binary values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = (y_predict > 0.5).astype(int)\n",
    "print(y_predict[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionmatrix=confusion_matrix(y_test,y_predict)\n",
    "print('The Confusion Matrix is displayed below :')\n",
    "print('')\n",
    "\n",
    "print(confusionmatrix)\n",
    "print('')\n",
    "\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "cm=confusion_matrix(y_test,y_predict)\n",
    "sns.heatmap(cm,annot=True,  fmt='.2f', xticklabels = [0,1] , yticklabels = [0,1])\n",
    "plt.ylabel('Observed')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model details "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tweaking the hyper parameters` \n",
    "\n",
    "1. We need to tweak the hyper parameter of the model to get results that are more accurate and low loss value for both training and validation data without over fitting the model .\n",
    "\n",
    "2. We would need to find the number of epochs where the performance/accuracy is better than what we had tried previously.We started with 500 epochs and a batch size of 100 and then iterated the process to find the best batch size and optimal number of epochs \n",
    "\n",
    "`Interpreting the charts` \n",
    "\n",
    "1. Accuracy/Recall - We see that there’s  no improvement in validation accuracy/recall after 100 epochs ,in fact the accuracy seems to be slightly dropping after 100 epochs.We see over fitting here \n",
    "\n",
    "2. Loss function - We see that clearly here there is no drop in loss after 50-75 epochs \n",
    "\n",
    "`Prediction using the test data set` \n",
    "\n",
    "1. We predict the target variable on the unseen test data and see the top 5 values to see if the array reflects the probability values .\n",
    "2. Since the output is using sigmoid ,we get the probabilities of the target variable .\n",
    "3. We will now set a threshold on top of the probabilities ,so anything >0.5 will give us 1 and less than 0.5 will give 0 .\n",
    "4. We use this output to print the confusion matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Modeling using Recall as primary metric - An experiment "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epoks=200\n",
    "neurons=[64,32,1]\n",
    "activation=['tanh','sigmoid']\n",
    "batch_size=[10,20,30]\n",
    "learning_rate=0.0001\n",
    "optimizer=[optimizers.Adam(learning_rate=learning_rate),\n",
    "           optimizers.SGD(learning_rate=learning_rate),\n",
    "           optimizers.RMSprop(learning_rate=learning_rate)]\n",
    "\n",
    "def dnn_model():\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Dense(neurons[0], input_dim=x_train.shape[1],activation = activation[0]))\n",
    "    model.add(Dense(neurons[1], activation = activation[0]))\n",
    "    model.add(Dense(neurons[2], activation = activation[1]))\n",
    "\n",
    "    model.compile(optimizer=optimizer[0],loss='binary_crossentropy',metrics=[tf.keras.metrics.Recall()])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model=dnn_model()\n",
    "\n",
    "history = model.fit(x_train_std,y_train, \n",
    "                    epochs=200, \n",
    "                    batch_size=20,\n",
    "                    validation_data=(x_val_std,y_val)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting the recall and loss function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`As an experiment and an alternative to the Accuracy metric ,we plot Recall and see if it gives us results that are more favourable to the business`\n",
    "\n",
    "N.B - I've not kept the code below inactive after checking the metrics ."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "acc      = history.history[     'recall' ]\n",
    "val_acc  = history.history[ 'val_recall' ]\n",
    "loss     = history.history[    'loss' ]\n",
    "val_loss = history.history['val_loss' ]\n",
    "\n",
    "epochs   = range(len(acc)) # Get number of epochs\n",
    "\n",
    "\n",
    "plt.plot  ( epochs,     acc ,label='training')\n",
    "plt.plot  ( epochs, val_acc,label='validation' )\n",
    "plt.title ('Training and validation recall')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot  ( epochs,     loss , label='training')\n",
    "plt.plot  ( epochs, val_loss , label='validation')\n",
    "plt.title ('Training and validation loss'   )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_predict=model.predict(x_test_std)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_predict = (y_predict > 0.5).astype(int)\n",
    "print(y_predict[:5])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cm=confusion_matrix(y_test,y_predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "confusionmatrix=confusion_matrix(y_test,y_predict)\n",
    "print('The Confusion Matrix is displayed below :')\n",
    "print('')\n",
    "\n",
    "print(confusionmatrix)\n",
    "print('')\n",
    "\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "cm=confusion_matrix(y_test,y_predict)\n",
    "sns.heatmap(cm,annot=True,  fmt='.2f', xticklabels = [0,1] , yticklabels = [0,1])\n",
    "plt.ylabel('Observed')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####         Conclusions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "` Business Insights `\n",
    "\n",
    "True Negative (observed=0,predicted=0)\n",
    "\n",
    "Predicted that the customer would not exit and they actually do not .\n",
    "\n",
    "False Positive (observed=0,predicted=1)\n",
    "\n",
    "Predicted that the customer would exit the bank  while the customer did not.\n",
    "\n",
    "True Negative (observed=0,predicted=0)\n",
    "\n",
    "Predicted that the customer would not exit the bank and the customer did not.\n",
    "\n",
    "False Negative(observed=1,predicted=0)\n",
    "\n",
    "Predicted the customer would not exit the bank when the customer did.\n",
    "\n",
    "`Metrics of main interest`\n",
    "\n",
    "From the problem statement given for the project,we look at the predictions in terms of accurate predictions of bank exits.\n",
    "\n",
    "\n",
    "*** Experiment 1 *** \n",
    "`Accuracy at 87% and Recall at 44%`\n",
    "\n",
    "***True Classifications*** Of the 1000 records that were used in the test data ,we have 777 predicted as True negatives  and 82 were predicted as positives and they are positive ,that is customer exited the bank.This is 86% accuracy .Of all those that were predicted as leaving or staying with the bank 86% of them were correctly done.\n",
    "\n",
    "We see that this value in our predicted value is not drastically different to the training/test data accuracy.\n",
    "\n",
    "**** Experiment 2 - Recall as a main metric ***\n",
    "`An alternate approach by looking at ***Recall*** as a main metric instead of Accuracy` \n",
    "\n",
    "As an experiment we also look at recall numbers since this seems more like a relevant metric to the business that just accuracy ,in fact accuracy and recall could be used in conjunction to decide on the best model\n",
    "\n",
    "`Accuracy at 87 % Recall at 47%`\n",
    "\n",
    "The ***False negatives*** The lower this number ,the better it is .These are the customers that we predict as not exiting the bank and they actually exit .Our model above ,shows low number of False negatives in the data compared to the one with Accuarcy as main metric.\n",
    "\n",
    "The ***True positives*** number has also gone up in the current model,which means that the  predictions made that the customer would buy a personal loan matches the actual.\n",
    "\n",
    "The ***False Positives number*** False positives have gone down ,indicating an overall error going down when we considered Recall as main metric.\n",
    "Whilst the Accuracy has remained the same ,while Recall,Precision f1 score have all gone up  by a small %\n",
    "\n",
    "*** Experiment - 3 + SMOTE  ***\n",
    "\n",
    "Using SMOTE to upsample the data ,since there's class imbalance .\n",
    "\n",
    "`Accuracy at 81% and Recall at 65 %`\n",
    "\n",
    "This would be ideal if we want to reduce the False Negatives (We predict the customers would not exit and they DO exit) ,While also trying to strike a fair balance with teh accuracy  at 81 % .F1 score & Recall are much better than the other models and the accuracy is a little compromised in this case . Needs further adjustment on the hyperparameters.\n",
    "\n",
    "This boils down to concluding that these are the different options provided to teh business and the most important metric needs to be decided and then accordingly we pick the best model from the 3 experiments we did.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BankChurnModeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
