{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Objective "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentiment analysis job about the problems of each major U.S. airline. The twitter data sentiments are classed as positive, negative, and neutral ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt# matplotlib.pyplot plots data\n",
    "%matplotlib inline \n",
    "from sklearn.model_selection import train_test_split\n",
    "import missingno as msno\n",
    "import warnings\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries.\n",
    "import re, string, unicodedata\n",
    "import pandas as pd\n",
    "import nltk           \n",
    "\n",
    "# Natural language processing tool-kit\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "import contractions\n",
    "from bs4 import BeautifulSoup                 # Beautiful soup is a parsing library that can use different parsers.\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet    # Stopwords, and wordnet corpus\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install and import necessary libraries.\n",
    "\n",
    "#!pip install contractions\n",
    "\n",
    "import re, string, unicodedata                          # Import Regex, string and unicodedata.\n",
    "import contractions                                     # Import contractions library.\n",
    "from bs4 import BeautifulSoup                           # Import BeautifulSoup.\n",
    "\n",
    "import numpy as np                                      # Import numpy.\n",
    "import pandas as pd                                     # Import pandas.\n",
    "import nltk                                             # Import Natural Language Tool-Kit.\n",
    "\n",
    "nltk.download('stopwords')                              # Download Stopwords.\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords                       # Import stopwords.\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize  # Import Tokenizer.\n",
    "from nltk.stem.wordnet import WordNetLemmatizer         # Import Lemmatizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the tweet data from the Tweets CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_checks(df):\n",
    "    \n",
    "    print('='*50)\n",
    "    print('Shape of the dataframe is: \\n',df.shape)\n",
    "    print('='*50)\n",
    "    print('Basic stats for the data: \\n',df.describe())\n",
    "    print('='*50)\n",
    "    print('Data type and info :')\n",
    "    print(df.info())\n",
    "    print('='*50)\n",
    "    print('Missing value information : \\n',df.isnull().any())\n",
    "    print('='*50)\n",
    "    print('Sum of missing values if any : \\n',df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_checks(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### EDA - Part 1\n",
    "\n",
    "1. There are a total of 14641 records in the tweet reviews and 15 columns\n",
    "\n",
    "2. Airline sentiment confidence varies between a minimum of 0.34 and a mean value of 0.9\n",
    "\n",
    "3. The highest number of retweets are 44\n",
    "\n",
    "4. All the columns have data in the object datatype\n",
    "\n",
    "5. There is missing values in certain fields - negative reason, negative reason confidence, airline sentiment gold, negative reason gold, tweet location and user timezone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by Airline and the Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.groupby(['airline','airline_sentiment']).size().unstack().plot(kind='bar',figsize=(11, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by Sentiment - value counts and bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.groupby('airline_sentiment').size().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(data1.airline_sentiment.value_counts(normalize=True)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Number of reviews by Airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of tweets for each airline \\n \",data1.groupby('airline')['airline_sentiment'].count().sort_values(ascending=False))\n",
    "airlines= ['US Airways','United','American','Southwest','Delta','Virgin America']\n",
    "plt.figure(1,figsize=(12, 12))\n",
    "for i in airlines:\n",
    "    indices= airlines.index(i)\n",
    "    plt.subplot(2,3,indices+1)\n",
    "    new_df=data1[data1['airline']==i]\n",
    "    count=new_df['airline_sentiment'].value_counts()\n",
    "    Index = [1,2,3]\n",
    "    plt.bar(Index,count, color=['pink', 'orange', 'lightblue'])\n",
    "    plt.xticks(Index,['negative','neutral','positive'])\n",
    "    plt.ylabel('Mood Count')\n",
    "    plt.xlabel('Mood')\n",
    "    plt.title('Count of Moods of '+i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Sentiment Word Clouds - Negative and positive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud,STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Negative Sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=data1[data1['airline_sentiment']=='negative']\n",
    "words = ' '.join(new_df['text'])\n",
    "cleaned_word = \" \".join([word for word in words.split()\n",
    "                            if 'http' not in word\n",
    "                                and not word.startswith('@')\n",
    "                                and word != 'RT'\n",
    "                            ])\n",
    "wordcloud = WordCloud(stopwords=STOPWORDS,\n",
    "                      background_color='black',\n",
    "                      width=3000,\n",
    "                      height=2500\n",
    "                     ).generate(cleaned_word)\n",
    "plt.figure(1,figsize=(12, 12))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Positive Sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=data1[data1['airline_sentiment']=='positive']\n",
    "words = ' '.join(new_df['text'])\n",
    "cleaned_word = \" \".join([word for word in words.split()\n",
    "                            if 'http' not in word\n",
    "                                and not word.startswith('@')\n",
    "                                and word != 'RT'\n",
    "                            ])\n",
    "wordcloud = WordCloud(stopwords=STOPWORDS,\n",
    "                      background_color='black',\n",
    "                      width=3000,\n",
    "                      height=2500\n",
    "                     ).generate(cleaned_word)\n",
    "plt.figure(1,figsize=(12, 12))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reasons for negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['negativereason'].nunique()\n",
    "\n",
    "NR_Count=dict(data1['negativereason'].value_counts(sort=False))\n",
    "def NR_Count(Airline):\n",
    "    if Airline=='All':\n",
    "        a=data1\n",
    "    else:\n",
    "        a=data1[data1['airline']==Airline]\n",
    "    count=dict(a['negativereason'].value_counts())\n",
    "    Unique_reason=list(data1['negativereason'].unique())\n",
    "    Unique_reason=[x for x in Unique_reason if str(x) != 'nan']\n",
    "    Reason_frame=pd.DataFrame({'Reasons':Unique_reason})\n",
    "    Reason_frame['count']=Reason_frame['Reasons'].apply(lambda x: count[x])\n",
    "    return Reason_frame\n",
    "def plot_reason(Airline):\n",
    "    \n",
    "    a=NR_Count(Airline)\n",
    "    count=a['count']\n",
    "    Index = range(1,(len(a)+1))\n",
    "    plt.bar(Index,count, color=['hotpink','pink','lightblue','lightgreen','violet','orange','gray','cyan','purple','orange'])\n",
    "    plt.xticks(Index,a['Reasons'],rotation=90)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Reason')\n",
    "    plt.title('Count of Reasons for '+Airline)\n",
    "    \n",
    "plot_reason('All')\n",
    "plt.figure(2,figsize=(13, 13))\n",
    "for i in airlines:\n",
    "    indices= airlines.index(i)\n",
    "    plt.subplot(2,3,indices+1)\n",
    "    plt.subplots_adjust(hspace=0.9)\n",
    "    plot_reason(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### EDA - part 2\n",
    "\n",
    "1. There are an overall of 62% negative tweets followed by 21.16 neutral and 16% of positive tweets\n",
    "2. The highest number of negative tweets are for United followed by US Airways and American \n",
    "3. The highest number of positive tweets are for Delta followed by Southwest and united .\n",
    "4. The positive ,negative and neutral reviews are closest in Virgin America,Delta and Southwest indicating an overall satisfactory customer sentiment.\n",
    "5. The negative word clouds indicate issues related to flight,bag,customer service ,help\n",
    "6. Issues raised in negative reviews were majorly customer service issues followed by late flight and bad flight experience\n",
    "7. Breaking down further we see that the negative reviews for US airways and United are due to Customer Service and late flights ,American Airline shows negative reviews due to Customer service issues, late/cancelled flights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping unnecessary columns** \n",
    "\n",
    "`Only extracting the useful columns for the sentiment analysis and discarding the remainder of the columns` \n",
    "\n",
    "1.From the original dataset we drop all columns except for Airline_sentiment and text \n",
    "2.There is no missing values in this data \n",
    "\n",
    "**Preprocessing of the text data**\n",
    "\n",
    "`We go through the following steps to pre process the text data :`\n",
    "\n",
    "1. Remove HTML tags - remove '<.*?>'\n",
    "\n",
    "2. Replace contractions - expand any contractions \n",
    "\n",
    "3. Remove numbers \n",
    "\n",
    "4. Tokenization - tokenize the text\n",
    "\n",
    "5. Remove stop words - form a list of stop words and remove those from the text\n",
    "\n",
    "6. Lemmatize the data\n",
    "\n",
    "7. Join the words in the list of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data1[['airline_sentiment', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_checks(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Remove Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_contractions(text):\n",
    "    \"\"\"Replace contractions in string of text\"\"\"\n",
    "    return contractions.fix(text)\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: replace_contractions(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "  text = re.sub(r'\\d+', '', text)\n",
    "  return text\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: remove_numbers(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Remove HTML tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "TAG_RE = re.compile('<.*?>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "data['text']=data['text'].apply(lambda x:remove_tags(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data.apply(lambda row: nltk.word_tokenize(row['text']), axis=1) # Tokenization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "\n",
    "customlist = ['not', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn',\n",
    "        \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\n",
    "        \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn',\n",
    "        \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "# Set custom stop-word's list as not, couldn't etc. words matter in Sentiment, so not removing them from original data.\n",
    "\n",
    "stopwords = list(set(stopwords) - set(customlist))                              "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_list(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "      new_words.append(lemmatizer.lemmatize(word, pos='v'))\n",
    "    return new_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_stopwords(words)\n",
    "    words = lemmatize_list(words)\n",
    "    return ' '.join(words)\n",
    "\n",
    "data['text'] = data.apply(lambda row: normalize(row['text']), axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list=[each.split(\" \") for each in data['text']]\n",
    "\n",
    "#words_list # list of lists \n",
    "\n",
    "import itertools\n",
    "corpus=set(itertools.chain(*words_list))\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Applying Count and TFidf Vectorizers "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The data above is ready to start apply the count/tf idf vectorizers .The following will be the approach to apply the vectorization and classify the data \n",
    "\n",
    "1. Apply the count/tf idf vectorizers \n",
    "2. Generate an array of the vector object\n",
    "3. Split the training and testing from the main dataset\n",
    "4. Apply a classification alogorithm - Random Forest/Extra Trees Regressor\n",
    "5. Print the accuracy \n",
    "6. Print the 3x3 confusion matrix - We have 3 classes for Sentiment ,positive ,negative and neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Count Vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=1000)                # Keep only 1000 features as number of features will increase the processing time.\n",
    "data_features = vectorizer.fit_transform(data['text'])\n",
    "\n",
    "data_features = data_features.toarray()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment']=data['airline_sentiment'].apply(lambda x: 0 if x=='negative' else  (2 if x=='neutral' else 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['airline_sentiment'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Split the data into training and testing sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_features, labels,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Count Vectorizer - RF Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500, n_jobs=4)\n",
    "\n",
    "forest = forest.fit(X_train, y_train)\n",
    "\n",
    "print(forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score=forest.score(X_test,y_test)\n",
    "print('RandomForest Test Accuracy Score :',model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rf = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Count Vectorizer - ExtraTrees Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "xtrees = ExtraTreesClassifier(n_jobs=4,n_estimators=500)\n",
    "\n",
    "xtrees = xtrees.fit(X_train, y_train)\n",
    "\n",
    "print(xtrees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score=xtrees.score(X_test,y_test)\n",
    "print('Xtra Trees Test Accuracy Score :',model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_xt = xtrees.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RF model - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,result_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, result_rf)\n",
    "\n",
    "print(conf_mat)\n",
    "\n",
    "df_cm = pd.DataFrame(conf_mat, index = [i for i in \"123\"],\n",
    "                  columns = [i for i in \"123\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ExtraTrees-Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,result_xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conf_mat = confusion_matrix(y_test, result_xt)\n",
    "\n",
    "print(conf_mat)\n",
    "\n",
    "df_cm = pd.DataFrame(conf_mat, index = [i for i in \"123\"],\n",
    "                  columns = [i for i in \"123\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tf- IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "data_features = vectorizer.fit_transform(data['text'])\n",
    "\n",
    "data_features = data_features.toarray()\n",
    "\n",
    "data_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tf-idf vectorizer-RF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Random Forest to build model for the classification of reviews.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "forestvect = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "\n",
    "forestvect = forestvect.fit(X_train, y_train)\n",
    "\n",
    "print(forestvect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score=forestvect.score(X_test,y_test)\n",
    "print('Random Forest - TFIDF Test Accuracy Score :',model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rfvect = forestvect.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,result_rfvect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conf_mat = confusion_matrix(y_test, result_rfvect)\n",
    "\n",
    "print(conf_mat)\n",
    "\n",
    "df_cm = pd.DataFrame(conf_mat, index = [i for i in \"123\"],\n",
    "                  columns = [i for i in \"123\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tf-idf vectorizer-ExtraTrees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xtrees_vect = ExtraTreesClassifier(n_jobs=4,n_estimators=500)\n",
    "\n",
    "xtrees_vect = xtrees_vect.fit(X_train, y_train)\n",
    "\n",
    "print(xtrees_vect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score=xtrees_vect.score(X_test,y_test)\n",
    "print('Extra Trees regressor - TFIDF Test Accuracy Score :',model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_xtreesvect = xtrees_vect.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,result_xtreesvect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conf_mat = confusion_matrix(y_test, result_xtreesvect)\n",
    "\n",
    "print(conf_mat)\n",
    "\n",
    "df_cm = pd.DataFrame(conf_mat, index = [i for i in \"123\"],\n",
    "                  columns = [i for i in \"123\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results - TF IDF & Count Vectorizer - Randome Forest vs Extra Trees Regressor**\n",
    "\n",
    "\n",
    "`Count Vectorizer` \n",
    "\n",
    "1. We visually compare the results of 2 of the classifiers that have given best results from a list of classifiers tried :RandomForest Classifier and the ExtraTrees Classifier \n",
    "2. The accuracy is definitely better in the Extra Trees Regressor than in the Random Forest Regressor \n",
    "3. The accuracy on the Test set is 79% in the Extra Trees Regressor  while 77% accuracy in Random Forest Regressor \n",
    "4. The confusion Matrix and the classification report show FP,TN,TP,FN values .Comparing these values we conclude that the Extra Trees Regressor is a better model than Random Forest Classifier as the recall and f1 scores are better in Extra Trees regressor \n",
    "\n",
    "`TF IDF Vectorizer`\n",
    "\n",
    "1. Again, we visually compare the results of 2 of the classifiers that have given best results from a list of classifiers tried :RandomForest Classifier and the ExtraTrees Classifier\n",
    "2. The accuracy of the Extra Trees Regressor is better than the Random Forest Regressor ,78.5 % compared to 77.4%\n",
    "3. The recall,f1 score are better in Extra Trees regressor \n",
    "\n",
    "`Business Insights`\n",
    "\n",
    "\n",
    "True Negative (observed=0,predicted=0)\n",
    "\n",
    "False Positive (observed=0,predicted=1)\n",
    "\n",
    "True Negative (observed=0,predicted=0)\n",
    "\n",
    "False Negative(observed=1,predicted=0)\n",
    "\n",
    "\n",
    "The metric of main interest should in my opinion here be Accuracy as we are trying to gauge the number of customers that left a negative tweet and were recognized as a negative tweet and left a positive/neutral tweet and were right identified so .\n",
    "\n",
    "True negatives and True positives here enable us in analyzing the customer behavior correctly\n",
    "\n",
    "Although false positive and False negative numbers still have a significant impact on decision making ,identifying the reviews under the correct category is still of utmost importance.\n",
    "\n",
    "\n",
    "**We can therefore conclude that the Extra Trees Regressor is a better model as opposed to Random Forest model in enabling to make better business decisions**\n",
    "\n",
    "`N.B`\n",
    "\n",
    "1. The exercise was tried with multiple classifiers and they aren't all listed here keeping in mind the motive of the exercise ,only the 2 best models were handpicked and compared for both Count and TF IDF vectorizers\n",
    "2. The exercse was tested using just 2 classes instead of 1 and the accuracy seemed better in this case .However to retain the classes that were originally in the document we keep all 3 classes - positive negative and neutral \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
